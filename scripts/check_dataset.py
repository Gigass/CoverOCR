#!/usr/bin/env python3
"""
CoverOCR æ•°æ®é›†å®Œæ•´æ€§æ£€æŸ¥è„šæœ¬
æ£€æŸ¥å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶æ˜¯å¦åŒ¹é…ï¼Œæ•°æ®æ˜¯å¦åˆæ³•
"""

import json
import sys
from pathlib import Path
from PIL import Image

def check_dataset(dataset_path='data/annotations/dataset.json', images_dir='data/images'):
    print("ğŸ” å¼€å§‹æ£€æŸ¥æ•°æ®é›†...")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    dataset_file = Path(dataset_path)
    if not dataset_file.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ ‡æ³¨æ–‡ä»¶ {dataset_path}")
        return False
    
    images_path = Path(images_dir)
    if not images_path.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°å›¾ç‰‡ç›®å½• {images_dir}")
        return False
    
    # åŠ è½½æ ‡æ³¨æ–‡ä»¶
    with open(dataset_file, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
    
    print(f"âœ… æ ‡æ³¨æ–‡ä»¶ç‰ˆæœ¬: {dataset.get('version', 'unknown')}")
    print(f"âœ… å¯¼å‡ºæ—¥æœŸ: {dataset.get('export_date', 'unknown')}")
    print(f"âœ… å£°æ˜å›¾ç‰‡æ•°é‡: {dataset.get('total_images', 0)}")
    print()
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_images = len(dataset['images'])
    total_regions = 0
    annotated_regions = 0
    missing_images = []
    invalid_bboxes = []
    invalid_point_sizes = []
    
    # æ£€æŸ¥æ¯å¼ å›¾ç‰‡
    for idx, img_data in enumerate(dataset['images'], 1):
        image_path = Path(images_dir) / Path(img_data['image_path']).name
        
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        if not image_path.exists():
            missing_images.append(img_data['image_path'])
            print(f"âŒ [{idx}/{total_images}] å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
            continue
        
        # åŠ è½½å›¾ç‰‡éªŒè¯å°ºå¯¸
        try:
            img = Image.open(image_path)
            actual_width, actual_height = img.size
            
            if actual_width != img_data['image_width'] or actual_height != img_data['image_height']:
                print(f"âš ï¸  [{idx}/{total_images}] å›¾ç‰‡å°ºå¯¸ä¸åŒ¹é…: {image_path}")
                print(f"    æ ‡æ³¨: {img_data['image_width']}x{img_data['image_height']}")
                print(f"    å®é™…: {actual_width}x{actual_height}")
        except Exception as e:
            print(f"âŒ [{idx}/{total_images}] æ— æ³•æ‰“å¼€å›¾ç‰‡: {image_path} ({e})")
            continue
        
        # æ£€æŸ¥æ ‡æ³¨
        for ann in img_data['annotations']:
            total_regions += 1
            
            # æ£€æŸ¥æ˜¯å¦å·²æ ‡æ³¨
            if ann['font_family'] and ann['point_size']:
                annotated_regions += 1
            
            # æ£€æŸ¥è¾¹ç•Œæ¡†
            bbox = ann['bbox']
            if len(bbox) != 4:
                invalid_bboxes.append((image_path.name, ann['id']))
            elif not (0 <= bbox[0] < bbox[2] <= actual_width and 
                     0 <= bbox[1] < bbox[3] <= actual_height):
                invalid_bboxes.append((image_path.name, ann['id']))
            
            # æ£€æŸ¥ç£…å€¼
            if ann['point_size'] and not (5 <= ann['point_size'] <= 100):
                invalid_point_sizes.append((image_path.name, ann['id'], ann['point_size']))
        
        print(f"âœ… [{idx}/{total_images}] {image_path.name}: {len(img_data['annotations'])} ä¸ªåŒºåŸŸ")
    
    # è¾“å‡ºç»Ÿè®¡
    print()
    print("=" * 60)
    print("ğŸ“Š æ•°æ®é›†ç»Ÿè®¡")
    print("=" * 60)
    print(f"æ€»å›¾ç‰‡æ•°: {total_images}")
    print(f"æ€»æ–‡å­—åŒºåŸŸæ•°: {total_regions}")
    print(f"å·²æ ‡æ³¨åŒºåŸŸæ•°: {annotated_regions} ({annotated_regions/total_regions*100:.1f}%)")
    print(f"æœªæ ‡æ³¨åŒºåŸŸæ•°: {total_regions - annotated_regions}")
    print()
    
    # è¾“å‡ºé—®é¢˜
    has_errors = False
    
    if missing_images:
        has_errors = True
        print("âŒ ç¼ºå¤±çš„å›¾ç‰‡:")
        for img in missing_images:
            print(f"   - {img}")
        print()
    
    if invalid_bboxes:
        has_errors = True
        print("âŒ æ— æ•ˆçš„è¾¹ç•Œæ¡†:")
        for img_name, region_id in invalid_bboxes[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"   - {img_name}, åŒºåŸŸ #{region_id}")
        if len(invalid_bboxes) > 10:
            print(f"   ... è¿˜æœ‰ {len(invalid_bboxes) - 10} ä¸ª")
        print()
    
    if invalid_point_sizes:
        has_errors = True
        print("âŒ å¼‚å¸¸çš„ç£…å€¼:")
        for img_name, region_id, pt in invalid_point_sizes[:10]:
            print(f"   - {img_name}, åŒºåŸŸ #{region_id}: {pt}pt")
        if len(invalid_point_sizes) > 10:
            print(f"   ... è¿˜æœ‰ {len(invalid_point_sizes) - 10} ä¸ª")
        print()
    
    # æ€»ç»“
    print("=" * 60)
    if has_errors:
        print("âš ï¸  å‘ç°é—®é¢˜ï¼Œè¯·ä¿®æ­£åå†è®­ç»ƒæ¨¡å‹")
        return False
    else:
        print("âœ… æ•°æ®é›†æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹")
        return True

if __name__ == '__main__':
    dataset_path = sys.argv[1] if len(sys.argv) > 1 else 'data/annotations/dataset.json'
    images_dir = sys.argv[2] if len(sys.argv) > 2 else 'data/images'
    
    success = check_dataset(dataset_path, images_dir)
    sys.exit(0 if success else 1)
